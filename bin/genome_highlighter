from typing import TextIO
from pandas import DataFrame
from datetime import datetime
from clustal_highlighter.modules.highlights import Highlights
from clustal_highlighter.modules.variant_handler import *
from clustal_highlighter.modules.file_handler import read_diverse_fimo_file
import argparse
import os
from subprocess import call
from pathlib import Path
import logging

from clustal_highlighter.modules.logger import *
logger = logging.getLogger('genome_highlighter')

def generate_dependencies(args) -> Highlights:
    colors = ['blue', 'red']
    html_colors = ['Aqua', 'PaleVioletRed']
    working_directory = None
    reports_generated = 0
    reports_requested = 0

    if args.output_dir != None:
        os.makedirs(args.output_dir, exist_ok=True)
        absolute_path = os.path.expanduser(args.output_dir)
        working_directory = os.path.abspath(absolute_path)
    else:
        global_home = os.path.expanduser('~/highlights_output')
        args.output_dir = global_home
        if not os.path.exists(global_home):
            os.makedirs(global_home)
        working_directory = global_home
        
    logging.basicConfig(filename=f'{working_directory}/tmp.log', filemode='w', level=logging.DEBUG)

    info(logger, f'Program Start Time: {datetime.now()}')
    
    print("Output and Working directory is at: " + working_directory)
    
    peak_locations = get_peak_locations(args.peaks)
    keys = list(peak_locations.keys())
    
    #TODO: Sequence name, motif name, number of matches found per file
    #TODO: Make the sequence name and motif name as a composite key
    info(logger, f'Successfully read in peaks from {args.peaks}. Peak keys as list: {keys}')
    for key in peak_locations:
        info(logger, f'Chromosome {key} has {len(peak_locations[key])} peaks')

    print("Peaks loaded")

    print("Loading sequence file...")
    
    seq_dict = read_fasta_file(args.seq_file)
    seq_keys = list(seq_dict.keys())
        
    info(logger, f'Successfully read in sequence file from: {args.seq_file}. Sequence keys as list: {seq_keys}')

    print("Sequence file loaded")

    valid_keys = []
    for seq_key in seq_keys:
        for key in keys:    
            if key in seq_key:
                valid_keys.append(seq_key)
    for seq_key in seq_keys:
        if seq_key not in valid_keys:
            del seq_dict[seq_key]
        else:
            seq_dict[seq_key.split('|', 1)[0].strip()] = seq_dict.pop(seq_key)
                    
    seq_keys = list(seq_dict.keys())
    
    info(logger, f'Removed excess sequences. Sequences saved: {seq_keys}')
    if seq_keys == []:
        raise Exception('No sequences found that match provided keys found in BED file')

    vcf_df = pd.DataFrame()
    if args.variant_data:
        print("Loading VCF...")
        
        info(logger, f'VCF added. Loading variant data from {args.variant_data}')
        
        vcf_df = read_vcf_into_dataframe(args.variant_data)
        
        info(logger, f'From the VCF file provided, {vcf_df.shape[0]} rows (variants) and {vcf_df.shape[1]} columns were loaded')
        print("VCF Loaded")
    else:
        warning(logger, 'No VCF given. Variant data will not be added.')

    for chromosome in peak_locations:
        print(f"Processing chromosome: {chromosome}")
        
        info(logger, f'Chromosome {chromosome} being processed')
        
        chromosome_seq = None
        file_name = None
        for file in seq_keys:
            if chromosome in file:
                chromosome_seq = seq_dict[file]
                file_name = file

        all_sequences = {}
        motifs = None
                
        for start, end in peak_locations[chromosome]:
            reports_requested += 1
            seq = chromosome_seq[start-1:end]

            single_seq_dict = {}
            single_seq_dict[f'{file_name}_{start}_{end}'] = seq

            all_sequences[(start, end)] = single_seq_dict
            
        info(logger, f'For Chromosome {chromosome}, {reports_requested} sequences have been gathered')

        file_path = print_fasta(all_sequences, f'{working_directory}/{file_name}')

        fimo_highlights = []
        motifs = generate_tuple_motifs(args.motif_files)

        print("Generating fimo tsv")

        for motif_name, motif_path in motifs:
            motif_and_df, file_paths = generate_fimo_output(
                file_path, motif_path, motif_name, working_directory)

            fimo_highlights.append(motif_and_df)
            info(logger, f'Fimo successfully ran. File used: {motif_path}')
        
        print("Generating output...")
        for start, end in peak_locations[chromosome]:
            single_seq_dict = all_sequences[((start, end))]

            temp_highlight = Highlights(single_seq_dict, start, end)

            if args.variant_data and not vcf_df.empty:
                max_missing_frac = args.max_missing_frac
                min_allele_freq = args.min_allele_freq

                # Guard clauses to adjust data as necessary
                if max_missing_frac is not None:
                    verify_valid_decimals(max_missing_frac, "max-missing-frac")
                if min_allele_freq is not None:
                    verify_valid_decimals(min_allele_freq, "min-allele-freq")
                
                # TO:DO I did this with default parameters. I don't know why it's not just running it once. 
                # I should just check for None in add_variant_data.   
                if max_missing_frac is None and min_allele_freq is None:
                    temp_highlight.add_variant_data(vcf_df)
                elif max_missing_frac is not None and min_allele_freq is not None:
                    temp_highlight.add_variant_data(
                        vcf_df, max_missing_frac, min_allele_freq)
                elif max_missing_frac is not None:
                    temp_highlight.add_variant_data(
                        vcf_df, max_missing_frac=max_missing_frac)
                else:
                    temp_highlight.add_variant_data(
                        vcf_df, min_allele_freq=min_allele_freq)

            for index, (motif_name, motif_df, working_directory) in enumerate(fimo_highlights):
                seq_name = list(single_seq_dict.keys())[0]
                motifs = motif_df.loc[motif_df['sequence_name'] == seq_name]
                
                motif_path = print_fimo_subset(motifs, working_directory)
                temp_highlight.add_highlights(
                    motif_name, motif_path, colors[index], html_colors[index])
                
            output_path = os.path.abspath(
                f'{args.output_dir}/{file_name}/{file_name}-{start}-{end}.html')

            if not os.path.exists(f'{args.output_dir}/{file_name}'):
                os.makedirs(f'{args.output_dir}/{file_name}')

            html_string_to_output(
                temp_highlight.generate_html_file(), output_path)
            reports_generated += 1
            
        print(f'output at: {working_directory}{file_name}')
    # Stats to verify everything is working
    #this needs to be in {} checks. I'll leave here for now ig...   
    if reports_generated == reports_requested:
        info(logger, f'Sequenecs gathered. reports requested: {reports_requested} vs reports generated: {reports_generated}')
    else:
        warning(logger, f'Sequenecs gathered. reports requested: {reports_requested} vs reports generated: {reports_generated}') 
    
    #check for stats flags and do stats things
    if args.summary_stats:
        print("This was the summary stats argument")
        pass

    if args.per_seq_stats:
        print("this was the per seq stats argument")
        pass
    
    #Do all of my check validations here
    check_warnings()

def add_log(log_file: TextIO, log: str):
    log_file.write(f'{log}\n', 'a')

def open_logfile(workspace, filename):
    log_file = open(f'{workspace}{filename}', 'w')
    return log_file

def print_fimo_subset(motif_df: DataFrame, working_directory ):
    file_path = f'{working_directory}/fimo_subset.tsv'
    motif_df.to_csv(file_path, index=False, sep="\t", header=True)
    return file_path

def print_fasta(all_sequences, output_path):
    file_path = f'{output_path}.fasta'
    os.makedirs(os.path.dirname(file_path), exist_ok=True)
    out = open(file_path, 'w')
    for key in all_sequences:
        start, end = key
        sequence_dict = all_sequences[key]
        for seq_name in sequence_dict:
            seq = sequence_dict[seq_name]
            out.write(f'>{seq_name}\n{seq}\n')

    out.close()
    return file_path

def generate_tuple_motifs(motifs):
    motif_pairs = []
    for i, j in zip(motifs[0::2], motifs[1::2]):
        motif_pairs.append((i, j))

    return motif_pairs


def generate_fimo_output(seq_path, motif_path, motif_name, output_path):
    seq_path = os.path.abspath(seq_path)
    basename_no_ending = Path(seq_path).stem
    file_paths = set()
    output_path = output_path + "/fimo"
    fimo_directory = f"{output_path}/{basename_no_ending}/{motif_name}/"
    os.makedirs(os.path.dirname(fimo_directory), exist_ok=True)
    call(f"run_fimo_on_file {seq_path} {motif_name} {motif_path} {output_path}", shell=True)

    fimo_file = fimo_directory + "/fimo.tsv"
    fimo_df = read_diverse_fimo_file(fimo_file)
    
    return (motif_name, fimo_df, fimo_directory), file_paths


def verify_valid_decimals(value, value_desc):
    if value < 0 or value > 1:
        raise argparse.ArgumentTypeError(
            f"{value} is an invalid value for {value_desc}")


def parseargs():
    """
    generates and returns a namespace for the argument parser
    """
    parser = argparse.ArgumentParser(description="Caller")

    parser.add_argument("--seq-file",
                        type=str,
                        required=True,
                        help="Path to fasta formatted sequence file ")

    parser.add_argument("--motif-files",
                        type=str,
                        required=False,
                        nargs='+',
                        help="A list of motif_name motif_file_path tuples for all the motifs that you want in the output")

    parser.add_argument("--variant-data",
                        required=False,
                        help="Path to VCF file containing variant data")

    parser.add_argument("--peaks",
                        required=True,
                        help="Path to BED file containing the locations of the different regions that you want highlights of (i.e. the start and end of an enhancer region")

    parser.add_argument("--output-dir",
                        type=str,
                        required=True,
                        help="Output file directory. This will be used as a working directory as well")

    parser.add_argument("--max-missing-frac",
                        type=float,
                        nargs='?',
                        const=None,
                        required=False,
                        help="0-1 float representing what percent of missing allele information makes a variant not display")

    parser.add_argument("--min-allele-freq",
                        type=float,
                        nargs='?',
                        const=None,
                        required=False,
                        help="0-1 float representing what minimum percent appearance an allele must have in order for a variant to display")

    parser.add_argument("--per-seq-stats",
                        required=False,
                        action = 'store_true',
                        help="When present this flag allows for the generation of individual CSV files containing the statistics per every sequence given")
    
    parser.add_argument("--summary-stats",
                        required=False,
                        action = 'store_true',
                        help="When present this flag allows for the generation of a CSV file containing the statistics summarizing all sequences")
    
    
    return parser.parse_args()


def html_string_to_output(html_string, output_dir):
    # just writes the html string to out
    output = open(output_dir, 'w')
    output.write(html_string)
    output.close


if __name__ == "__main__":
    args = parseargs()
    if len(args.motif_files) % 2 != 0:
        print("\n--motif-files flag given an odd number of inputs, please use -h for more info")
        exit(0)
    else:
        generate_dependencies(args)
